{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_colwidth = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'POS.train'\n",
    "test_file = 'POS.test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_file, sep='\\t', header=None, names=['raw'])\n",
    "test_df = pd.read_csv(test_file, sep='\\t', header=None, names=['raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Pierre/NP Vinken/NP ,/, 61/CD years/NNS old/JJ ,/, will/MD join/VB the/DT board/NN as/IN a/DT nonexecutive/JJ director/NN Nov./NP 29/CD ./.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mr./NP Vinken/NP is/VBZ chairman/NN of/IN Elsevier/NP N.V./NP ,/, the/DT Dutch/NP publishing/VBG group/NN ./.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Rudolph/NP Agnew/NP ,/, 55/CD years/NNS old/JJ and/CC former/JJ chairman/NN of/IN Consolidated/NP Gold/NP Fields/NP PLC/NP ,/, was/VBD named/VBN a/DT nonexecutive/JJ director/NN of/IN this/DT British/JJ industrial/JJ conglomerate/NN ./.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A/DT form/NN of/IN asbestos/NN once/RB used/VBN to/TO make/VB Kent/NP cigarette/NN filters/NNS has/VBZ caused/VBN a/DT high/JJ percentage/NN of/IN cancer/NN deaths/NNS among/IN a/DT group/NN of/IN workers/NNS exposed/VBN to/TO it/PP more/RBR than/IN 30/CD years/NNS ago/IN ,/, researchers/NNS rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The/DT asbestos/NN fiber/NN ,/, crocidolite/NN ,/, is/VBZ unusually/RB resilient/JJ once/IN it/PP enters/VBZ the/DT lungs/NNS ,/, with/IN even/RB brief/JJ exposures/NNS to/TO it/PP causing/VBG symptoms/NNS that/WDT show/VBP up/IN decades/NNS later/JJ ,/, researchers/NNS said/VBD ./.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                           raw\n",
       "0                                                                                                                                                                 Pierre/NP Vinken/NP ,/, 61/CD years/NNS old/JJ ,/, will/MD join/VB the/DT board/NN as/IN a/DT nonexecutive/JJ director/NN Nov./NP 29/CD ./. \n",
       "1                                                                                                                                                                                               Mr./NP Vinken/NP is/VBZ chairman/NN of/IN Elsevier/NP N.V./NP ,/, the/DT Dutch/NP publishing/VBG group/NN ./. \n",
       "2                                                                Rudolph/NP Agnew/NP ,/, 55/CD years/NNS old/JJ and/CC former/JJ chairman/NN of/IN Consolidated/NP Gold/NP Fields/NP PLC/NP ,/, was/VBD named/VBN a/DT nonexecutive/JJ director/NN of/IN this/DT British/JJ industrial/JJ conglomerate/NN ./. \n",
       "3  A/DT form/NN of/IN asbestos/NN once/RB used/VBN to/TO make/VB Kent/NP cigarette/NN filters/NNS has/VBZ caused/VBN a/DT high/JJ percentage/NN of/IN cancer/NN deaths/NNS among/IN a/DT group/NN of/IN workers/NNS exposed/VBN to/TO it/PP more/RBR than/IN 30/CD years/NNS ago/IN ,/, researchers/NNS rep...\n",
       "4                 The/DT asbestos/NN fiber/NN ,/, crocidolite/NN ,/, is/VBZ unusually/RB resilient/JJ once/IN it/PP enters/VBZ the/DT lungs/NNS ,/, with/IN even/RB brief/JJ exposures/NNS to/TO it/PP causing/VBG symptoms/NNS that/WDT show/VBP up/IN decades/NNS later/JJ ,/, researchers/NNS said/VBD ./. "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df):\n",
    "    # Input: Raw sentence dataframe with only one column with sentences tagged with POS\n",
    "    # Output: 3 pandas series encoding P(W|T), P(T|<s>) and P(T(i+1)|Ti)\n",
    "    \n",
    "    # Calculate word given the tag probabilities\n",
    "    word_tag_prob = (\n",
    "        df\n",
    "        .assign(raw_split = lambda x: x['raw'].str.split())  # Split sentence into a list with elements like 'word/POS'\n",
    "        .drop(['raw'], axis=1)\n",
    "        .explode('raw_split')  # Put each element in separate rows\n",
    "        .reset_index(drop=True)\n",
    "        .assign(word_tag = lambda x: x['raw_split'].str.split('/'))  # Split the elements into word-tag pairs\n",
    "        .drop(['raw_split'], axis=1)\n",
    "        .assign(\n",
    "            word = lambda x: x['word_tag'].str[0],  # Separate words into different column\n",
    "            tag = lambda x: x['word_tag'].str[1],  # Separate tags into different column\n",
    "        )\n",
    "        .drop(['word_tag'], axis=1)\n",
    "        .groupby(by=['word', 'tag'])\n",
    "        .agg({'tag': 'count'})  # Get count of all word-tag combinations\n",
    "        .rename(columns={'tag': 'count'})\n",
    "        .reset_index()\n",
    "        .assign(\n",
    "            prob = lambda x: x['count']/x.groupby('tag')['count'].transform(sum)  # Get probability P(W|T)\n",
    "        )\n",
    "        .drop(['count'], axis=1)\n",
    "        .set_index(['word', 'tag'])['prob']  # Form a pandas series of probabilities\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Calculate the tag given sentence beginning probability\n",
    "    first_tag_prob = (\n",
    "        df\n",
    "        .assign(first_tag = lambda x: x['raw'].str.split().str[0].str.split('/').str[1])  # Extract tag of the first word\n",
    "        .groupby(by=['first_tag'])\n",
    "        .agg({'first_tag': 'count'})  # Count occurences of each first tag\n",
    "        .rename(columns={'first_tag': 'count'})\n",
    "        .assign(prob = lambda x: x['count']/x['count'].sum())  # Calculate P(T|<s>) since each row is an individual sentence\n",
    "        .drop(['count'], axis=1)['prob']  # Get probabilities pandas series\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Calculate probability of current tag given previous tag\n",
    "    tag_given_tag_prob = (\n",
    "        df\n",
    "        .assign(eos_tag=' EOS/EOS')\n",
    "        .assign(raw_mod = lambda x: (x['raw'] + x['eos_tag']).astype(str))  # Add an EOS tag to avoid conditioning probabilities on tags of previous sentences\n",
    "        .drop(['raw'], axis=1)\n",
    "        .assign(raw_split = lambda x: x['raw_mod'].str.split())  # Split sentences into word/POS elements\n",
    "        .drop(['raw_mod', 'eos_tag'], axis=1)\n",
    "        .explode('raw_split')  # Put each element in separate rows\n",
    "        .reset_index(drop=True)\n",
    "        .assign(given = lambda x: x['raw_split'].str.split('/').str[1])  # Extract the POS tags\n",
    "        .drop(['raw_split'], axis=1)\n",
    "        .assign(asked = lambda x: x['given'].shift(-1)).fillna('EndOfDocument')  # Bring the subsequent POS tag into same row\n",
    "        .groupby(by=['asked', 'given'])\n",
    "        .agg({'asked': 'count'})  # Get the count of Tn, T(n+1) combinations\n",
    "        .rename(columns={'asked': 'count'})\n",
    "        .reset_index()\n",
    "        .assign(prob = lambda x: x['count']/x.groupby(by=['given'])['count'].transform(sum))  # Calculate probability P(T(i+1)|Ti)\n",
    "        .set_index(['asked', 'given'])['prob']  # Get pandas series of probabilities\n",
    "    )\n",
    "    return word_tag_prob, first_tag_prob, tag_given_tag_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag_prob, first_tag_prob, tag_given_tag_prob = train(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(sentence_list, word_tag_prob, first_tag_prob, tag_given_tag_prob):\n",
    "    # Input: Sentence list with elements as each token\n",
    "    # Output: List with predicted POS tags for each token in the sentence\n",
    "    \n",
    "    def get_word_tag_prob(word, tag):\n",
    "        # Calculate P(W|T)\n",
    "        try:\n",
    "            return word_tag_prob[(word, tag)]\n",
    "        except:\n",
    "            return 1.0 \n",
    "    \n",
    "    def get_tag_set(word):\n",
    "        # Get total POS tags seen during training for the given word\n",
    "        try:\n",
    "            return word_tag_prob[word].index.tolist()\n",
    "        except:\n",
    "            return ['NP']\n",
    "    \n",
    "    def get_tag_given_tag_prob(this_tag, given_tag):\n",
    "        # Calculate P(T(i+1)|Ti)\n",
    "        try:\n",
    "            return tag_given_tag_prob[(this_tag, given_tag)]\n",
    "        except KeyError:\n",
    "            return 0.0\n",
    "    \n",
    "    score = dict()\n",
    "    back_ptr = dict()\n",
    "    \n",
    "    # Initialization\n",
    "    # Calculate score for all tags of the first word\n",
    "    first_word_tag_set = get_tag_set(sentence_list[0])\n",
    "    for tag in first_word_tag_set:\n",
    "        score[(tag, 0)] = get_word_tag_prob(sentence_list[0], tag)\n",
    "        back_ptr[(tag, 0)] = 0\n",
    "    \n",
    "    # Iteration\n",
    "    # Calculate score for all token-tags combinations\n",
    "    # Store best tag of previous word in back_ptr dictionary\n",
    "    for j, word in enumerate(sentence_list[1:]):\n",
    "        for tag in get_tag_set(word):\n",
    "            i = j + 1\n",
    "            prev_word_tag_set = get_tag_set(sentence_list[i-1])\n",
    "            t1 = get_word_tag_prob(word, tag)\n",
    "            t2_dict = {last_tag: score[(last_tag, i-1)] * get_tag_given_tag_prob(tag, last_tag) \n",
    "                       for last_tag in prev_word_tag_set}\n",
    "            t2 = max(t2_dict.values())\n",
    "            score[(tag, i)] = t1 * t2\n",
    "            back_ptr[(tag, i)] = max(t2_dict, key=t2_dict.get)\n",
    "\n",
    "    # Get all tags for last word and find the one with best score\n",
    "    final_word_tag_set = get_tag_set(sentence_list[-1])\n",
    "    last_scores = {tag: score[(tag, len(sentence_list) - 1)] for tag in final_word_tag_set}\n",
    "    final_word_tag = max(last_scores)\n",
    "    \n",
    "    final_tags = [final_word_tag]\n",
    "    this_tag = final_word_tag\n",
    "    # Iterate back through back_ptr to get the final POS tags for all tokens\n",
    "    for i in reversed(range(len(sentence_list))):\n",
    "        final_tags.append(back_ptr[(this_tag, i)])\n",
    "        this_tag = back_ptr[(this_tag, i)]\n",
    "    \n",
    "    return final_tags[::-1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(raw_df, word_tag_prob, first_tag_prob, tag_given_tag_prob):\n",
    "    # Input: Dataframe with raw sentences tagged with true POS and other probabilities from training\n",
    "    # Output: Dataframe with predicted POS tags\n",
    "    \n",
    "    def disassemble(raw_sentence):\n",
    "        sentence_list_with_tags = [term.split('/') for term in raw_sentence.split()]\n",
    "        sentence_list_without_tags = [term[0] for term in sentence_list_with_tags]\n",
    "        true_tags = [term[1] for term in sentence_list_with_tags]\n",
    "        return sentence_list_without_tags, true_tags\n",
    "\n",
    "    def assemble(sentence_list_without_tags, tags):\n",
    "        sentence_list_with_tags = [sentence_list_without_tags[i] + '/' + tags[i] for i in range(len(tags))]\n",
    "        return ' '.join(sentence_list_with_tags)\n",
    "    \n",
    "    correct_tags = 0\n",
    "    total_tags = 0\n",
    "    predicted_sentences = []\n",
    "    \n",
    "    for i in range(len(raw_df)):\n",
    "        raw_sentence = raw_df.iloc[i, 0]\n",
    "        sentence_list_without_tags, true_tags = disassemble(raw_sentence)\n",
    "        predicted_tags = predict_sentence(sentence_list_without_tags, word_tag_prob, first_tag_prob, tag_given_tag_prob)\n",
    "        correct_tags += (np.array(predicted_tags) == np.array(true_tags)).sum()\n",
    "        total_tags += len(true_tags)\n",
    "        assembled_sentence = assemble(sentence_list_without_tags, predicted_tags)\n",
    "        predicted_sentences.append(assembled_sentence)\n",
    "        \n",
    "    accuracy = round((float(correct_tags) * 100)/float(total_tags), 2)\n",
    "    df = pd.DataFrame(predicted_sentences, columns=['raw'])\n",
    "    print ('Accuracy: {}%'.format(accuracy))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentences = predict_text(test_df, word_tag_prob, first_tag_prob, tag_given_tag_prob)\n",
    "predicted_sentences.to_csv('POS.test.out', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
