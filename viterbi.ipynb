{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_colwidth = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'POS.train'\n",
    "test_file = 'POS.test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_file, sep='\\t', header=None, names=['raw'])\n",
    "test_df = pd.read_csv(test_file, sep='\\t', header=None, names=['raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Pierre/NP Vinken/NP ,/, 61/CD years/NNS old/JJ ,/, will/MD join/VB the/DT board/NN as/IN a/DT nonexecutive/JJ director/NN Nov./NP 29/CD ./.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mr./NP Vinken/NP is/VBZ chairman/NN of/IN Elsevier/NP N.V./NP ,/, the/DT Dutch/NP publishing/VBG group/NN ./.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Rudolph/NP Agnew/NP ,/, 55/CD years/NNS old/JJ and/CC former/JJ chairman/NN of/IN Consolidated/NP Gold/NP Fields/NP PLC/NP ,/, was/VBD named/VBN a/DT nonexecutive/JJ director/NN of/IN this/DT British/JJ industrial/JJ conglomerate/NN ./.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A/DT form/NN of/IN asbestos/NN once/RB used/VBN to/TO make/VB Kent/NP cigarette/NN filters/NNS has/VBZ caused/VBN a/DT high/JJ percentage/NN of/IN cancer/NN deaths/NNS among/IN a/DT group/NN of/IN workers/NNS exposed/VBN to/TO it/PP more/RBR than/IN 30/CD years/NNS ago/IN ,/, researchers/NNS rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The/DT asbestos/NN fiber/NN ,/, crocidolite/NN ,/, is/VBZ unusually/RB resilient/JJ once/IN it/PP enters/VBZ the/DT lungs/NNS ,/, with/IN even/RB brief/JJ exposures/NNS to/TO it/PP causing/VBG symptoms/NNS that/WDT show/VBP up/IN decades/NNS later/JJ ,/, researchers/NNS said/VBD ./.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                           raw\n",
       "0                                                                                                                                                                 Pierre/NP Vinken/NP ,/, 61/CD years/NNS old/JJ ,/, will/MD join/VB the/DT board/NN as/IN a/DT nonexecutive/JJ director/NN Nov./NP 29/CD ./. \n",
       "1                                                                                                                                                                                               Mr./NP Vinken/NP is/VBZ chairman/NN of/IN Elsevier/NP N.V./NP ,/, the/DT Dutch/NP publishing/VBG group/NN ./. \n",
       "2                                                                Rudolph/NP Agnew/NP ,/, 55/CD years/NNS old/JJ and/CC former/JJ chairman/NN of/IN Consolidated/NP Gold/NP Fields/NP PLC/NP ,/, was/VBD named/VBN a/DT nonexecutive/JJ director/NN of/IN this/DT British/JJ industrial/JJ conglomerate/NN ./. \n",
       "3  A/DT form/NN of/IN asbestos/NN once/RB used/VBN to/TO make/VB Kent/NP cigarette/NN filters/NNS has/VBZ caused/VBN a/DT high/JJ percentage/NN of/IN cancer/NN deaths/NNS among/IN a/DT group/NN of/IN workers/NNS exposed/VBN to/TO it/PP more/RBR than/IN 30/CD years/NNS ago/IN ,/, researchers/NNS rep...\n",
       "4                 The/DT asbestos/NN fiber/NN ,/, crocidolite/NN ,/, is/VBZ unusually/RB resilient/JJ once/IN it/PP enters/VBZ the/DT lungs/NNS ,/, with/IN even/RB brief/JJ exposures/NNS to/TO it/PP causing/VBG symptoms/NNS that/WDT show/VBP up/IN decades/NNS later/JJ ,/, researchers/NNS said/VBD ./. "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df):\n",
    "    # Input: Raw sentence dataframe with only one column with sentences tagged with POS\n",
    "    # Output: 3 pandas series encoding P(W|T), P(T|<s>) and P(T(i+1)|Ti)\n",
    "    \n",
    "    # Calculate word given the tag probabilities\n",
    "    word_tag_prob = (\n",
    "        df\n",
    "        .assign(raw_split = lambda x: x['raw'].str.split())  # Split sentence into a list with elements like 'word/POS'\n",
    "        .drop(['raw'], axis=1)\n",
    "        .explode('raw_split')  # Put each element in separate rows\n",
    "        .reset_index(drop=True)\n",
    "        .assign(word_tag = lambda x: x['raw_split'].str.split('/'))  # Split the elements into word-tag pairs\n",
    "        .drop(['raw_split'], axis=1)\n",
    "        .assign(\n",
    "            word = lambda x: x['word_tag'].str[0],  # Separate words into different column\n",
    "            tag = lambda x: x['word_tag'].str[1],  # Separate tags into different column\n",
    "        )\n",
    "        .drop(['word_tag'], axis=1)\n",
    "        .groupby(by=['word', 'tag'])\n",
    "        .agg({'tag': 'count'})  # Get count of all word-tag combinations\n",
    "        .rename(columns={'tag': 'count'})\n",
    "        .reset_index()\n",
    "        .assign(\n",
    "            prob = lambda x: x['count']/x.groupby('tag')['count'].transform(sum)  # Get probability P(W|T)\n",
    "        )\n",
    "        .drop(['count'], axis=1)\n",
    "        .set_index(['word', 'tag'])['prob']  # Form a pandas series of probabilities\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Calculate the tag given sentence beginning probability\n",
    "    first_tag_prob = (\n",
    "        df\n",
    "        .assign(first_tag = lambda x: x['raw'].str.split().str[0].str.split('/').str[1])  # Extract tag of the first word\n",
    "        .groupby(by=['first_tag'])\n",
    "        .agg({'first_tag': 'count'})  # Count occurences of each first tag\n",
    "        .rename(columns={'first_tag': 'count'})\n",
    "        .assign(prob = lambda x: x['count']/x['count'].sum())  # Calculate P(T|<s>) since each row is an individual sentence\n",
    "        .drop(['count'], axis=1)['prob']  # Get probabilities pandas series\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Calculate probability of current tag given previous tag\n",
    "    tag_given_tag_prob = (\n",
    "        df\n",
    "        .assign(eos_tag=' EOS/EOS')\n",
    "        .assign(raw_mod = lambda x: (x['raw'] + x['eos_tag']).astype(str))  # Add an EOS tag to avoid conditioning probabilities on tags of previous sentences\n",
    "        .drop(['raw'], axis=1)\n",
    "        .assign(raw_split = lambda x: x['raw_mod'].str.split())  # Split sentences into word/POS elements\n",
    "        .drop(['raw_mod', 'eos_tag'], axis=1)\n",
    "        .explode('raw_split')  # Put each element in separate rows\n",
    "        .reset_index(drop=True)\n",
    "        .assign(given = lambda x: x['raw_split'].str.split('/').str[1])  # Extract the POS tags\n",
    "        .drop(['raw_split'], axis=1)\n",
    "        .assign(asked = lambda x: x['given'].shift(-1)).fillna('EndOfDocument')  # Bring the subsequent POS tag into same row\n",
    "        .groupby(by=['asked', 'given'])\n",
    "        .agg({'asked': 'count'})  # Get the count of Tn, T(n+1) combinations\n",
    "        .rename(columns={'asked': 'count'})\n",
    "        .reset_index()\n",
    "        .assign(prob = lambda x: x['count']/x.groupby(by=['given'])['count'].transform(sum))  # Calculate probability P(T(i+1)|Ti)\n",
    "        .set_index(['asked', 'given'])['prob']  # Get pandas series of probabilities\n",
    "    )\n",
    "    return word_tag_prob, first_tag_prob, tag_given_tag_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag_prob, first_tag_prob, tag_given_tag_prob = train(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(sentence_list, word_tag_prob, first_tag_prob, tag_given_tag_prob):\n",
    "    # Input: Sentence list with elements as each token\n",
    "    # Output: List with predicted POS tags for each token in the sentence\n",
    "    \n",
    "    def get_word_tag_prob(word, tag):\n",
    "        # Calculate P(W|T)\n",
    "        try:\n",
    "            return word_tag_prob[(word, tag)]\n",
    "        except:\n",
    "            return 1.0 \n",
    "    \n",
    "    def get_tag_set(word):\n",
    "        # Get total POS tags seen during training for the given word\n",
    "        try:\n",
    "            return word_tag_prob[word].index.tolist()\n",
    "        except:\n",
    "            return ['NP']\n",
    "    \n",
    "    def get_tag_given_tag_prob(this_tag, given_tag):\n",
    "        # Calculate P(T(i+1)|Ti)\n",
    "        try:\n",
    "            return tag_given_tag_prob[(this_tag, given_tag)]\n",
    "        except KeyError:\n",
    "            return 0.0\n",
    "    \n",
    "    score = dict()\n",
    "    back_ptr = dict()\n",
    "    \n",
    "    # Initialization\n",
    "    # Calculate score for all tags of the first word\n",
    "    first_word_tag_set = get_tag_set(sentence_list[0])\n",
    "    for tag in first_word_tag_set:\n",
    "        score[(tag, 0)] = get_word_tag_prob(sentence_list[0], tag)\n",
    "        back_ptr[(tag, 0)] = 0\n",
    "    \n",
    "    # Iteration\n",
    "    # Calculate score for all token-tags combinations\n",
    "    # Store best tag of previous word in back_ptr dictionary\n",
    "    for j, word in enumerate(sentence_list[1:]):\n",
    "        for tag in get_tag_set(word):\n",
    "            i = j + 1\n",
    "            prev_word_tag_set = get_tag_set(sentence_list[i-1])\n",
    "            t1 = get_word_tag_prob(word, tag)\n",
    "            t2_dict = {last_tag: score[(last_tag, i-1)] * get_tag_given_tag_prob(tag, last_tag) \n",
    "                       for last_tag in prev_word_tag_set}\n",
    "            t2 = max(t2_dict.values())\n",
    "            score[(tag, i)] = t1 * t2\n",
    "            back_ptr[(tag, i)] = max(t2_dict, key=t2_dict.get)\n",
    "\n",
    "    # Get all tags for last word and find the one with best score\n",
    "    final_word_tag_set = get_tag_set(sentence_list[-1])\n",
    "    last_scores = {tag: score[(tag, len(sentence_list) - 1)] for tag in final_word_tag_set}\n",
    "    final_word_tag = max(last_scores)\n",
    "    \n",
    "    final_tags = [final_word_tag]\n",
    "    this_tag = final_word_tag\n",
    "    # Iterate back through back_ptr to get the final POS tags for all tokens\n",
    "    for i in reversed(range(len(sentence_list))):\n",
    "        final_tags.append(back_ptr[(this_tag, i)])\n",
    "        this_tag = back_ptr[(this_tag, i)]\n",
    "    \n",
    "    return final_tags[::-1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(raw_df, word_tag_prob, first_tag_prob, tag_given_tag_prob):\n",
    "    # Input: Dataframe with raw sentences tagged with true POS and other probabilities from training\n",
    "    # Output: Dataframe with predicted POS tags\n",
    "    \n",
    "    def disassemble(raw_sentence):\n",
    "        sentence_list_with_tags = [term.split('/') for term in raw_sentence.split()]\n",
    "        sentence_list_without_tags = [term[0] for term in sentence_list_with_tags]\n",
    "        true_tags = [term[1] for term in sentence_list_with_tags]\n",
    "        return sentence_list_without_tags, true_tags\n",
    "\n",
    "    def assemble(sentence_list_without_tags, tags):\n",
    "        sentence_list_with_tags = [sentence_list_without_tags[i] + '/' + tags[i] for i in range(len(tags))]\n",
    "        return ' '.join(sentence_list_with_tags)\n",
    "    \n",
    "    correct_tags = 0\n",
    "    total_tags = 0\n",
    "    predicted_sentences = []\n",
    "    \n",
    "    for i in range(len(raw_df)):\n",
    "        raw_sentence = raw_df.iloc[i, 0]\n",
    "        sentence_list_without_tags, true_tags = disassemble(raw_sentence)\n",
    "        predicted_tags = predict_sentence(sentence_list_without_tags, word_tag_prob, first_tag_prob, tag_given_tag_prob)\n",
    "        correct_tags += (np.array(predicted_tags) == np.array(true_tags)).sum()\n",
    "        print (' '.join(sentence_list_without_tags))\n",
    "        print (sentence_list_without_tags, '\\n', true_tags, '\\n', predicted_tags, '\\n'*3)\n",
    "        \n",
    "        total_tags += len(true_tags)\n",
    "        assembled_sentence = assemble(sentence_list_without_tags, predicted_tags)\n",
    "        predicted_sentences.append(assembled_sentence)\n",
    "        \n",
    "    accuracy = round((float(correct_tags) * 100)/float(total_tags), 2)\n",
    "    df = pd.DataFrame(predicted_sentences, columns=['raw'])\n",
    "    print ('Accuracy: {}%'.format(accuracy))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He said two brokerage firms had been approved and would begin operating shortly .\n",
      "['He', 'said', 'two', 'brokerage', 'firms', 'had', 'been', 'approved', 'and', 'would', 'begin', 'operating', 'shortly', '.'] \n",
      " ['PP', 'VBD', 'CD', 'NN', 'NNS', 'VBD', 'VBN', 'VBN', 'CC', 'MD', 'VB', 'VBG', 'RB', '.'] \n",
      " ['PP', 'VBD', 'CD', 'NN', 'NNS', 'VBD', 'VBN', 'VBN', 'CC', 'MD', 'VB', 'VBG', 'RB', '.'] \n",
      "\n",
      "\n",
      "\n",
      "The stock exchange , supervised by the National Economy Ministry , has a listing of 119 companies .\n",
      "['The', 'stock', 'exchange', ',', 'supervised', 'by', 'the', 'National', 'Economy', 'Ministry', ',', 'has', 'a', 'listing', 'of', '119', 'companies', '.'] \n",
      " ['DT', 'NN', 'NN', ',', 'VBN', 'IN', 'DT', 'NP', 'NP', 'NP', ',', 'VBZ', 'DT', 'NN', 'IN', 'CD', 'NNS', '.'] \n",
      " ['DT', 'NN', 'NN', ',', 'NP', 'IN', 'DT', 'NP', 'NP', 'NP', ',', 'VBZ', 'DT', 'NN', 'IN', 'CD', 'NNS', '.'] \n",
      "\n",
      "\n",
      "\n",
      "Trading volume in 1988 totaled 49.13 billion drachmas , down from 61.5 billion drachmas in 1987 .\n",
      "['Trading', 'volume', 'in', '1988', 'totaled', '49.13', 'billion', 'drachmas', ',', 'down', 'from', '61.5', 'billion', 'drachmas', 'in', '1987', '.'] \n",
      " ['NN', 'NN', 'IN', 'CD', 'VBD', 'CD', 'CD', 'NNS', ',', 'RB', 'IN', 'CD', 'CD', 'NNS', 'IN', 'CD', '.'] \n",
      " ['NN', 'NN', 'IN', 'CD', 'VBD', 'NP', 'CD', 'NP', ',', 'RB', 'IN', 'NP', 'CD', 'NP', 'IN', 'CD', '.'] \n",
      "\n",
      "\n",
      "\n",
      "Trading at the Athens Stock Exchange is conducted by open outcry and transactions are in cash with a 24-hour settlement .\n",
      "['Trading', 'at', 'the', 'Athens', 'Stock', 'Exchange', 'is', 'conducted', 'by', 'open', 'outcry', 'and', 'transactions', 'are', 'in', 'cash', 'with', 'a', '24-hour', 'settlement', '.'] \n",
      " ['NN', 'IN', 'DT', 'NP', 'NP', 'NP', 'VBZ', 'VBN', 'IN', 'JJ', 'NN', 'CC', 'NNS', 'VBP', 'IN', 'NN', 'IN', 'DT', 'JJ', 'NN', '.'] \n",
      " ['NN', 'IN', 'DT', 'NP', 'NP', 'NP', 'VBZ', 'VBN', 'IN', 'JJ', 'NN', 'CC', 'NNS', 'VBP', 'IN', 'NN', 'IN', 'DT', 'NP', 'NN', '.'] \n",
      "\n",
      "\n",
      "\n",
      "Foreign investors may buy and sell freely on the exchange .\n",
      "['Foreign', 'investors', 'may', 'buy', 'and', 'sell', 'freely', 'on', 'the', 'exchange', '.'] \n",
      " ['JJ', 'NNS', 'MD', 'VB', 'CC', 'VB', 'RB', 'IN', 'DT', 'NN', '.'] \n",
      " ['JJ', 'NNS', 'MD', 'VB', 'CC', 'VB', 'RB', 'IN', 'DT', 'NN', '.'] \n",
      "\n",
      "\n",
      "\n",
      "Orders for securities are placed directly with an official broker or through a bank operating in Greece .\n",
      "['Orders', 'for', 'securities', 'are', 'placed', 'directly', 'with', 'an', 'official', 'broker', 'or', 'through', 'a', 'bank', 'operating', 'in', 'Greece', '.'] \n",
      " ['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'RB', 'IN', 'DT', 'JJ', 'NN', 'CC', 'IN', 'DT', 'NN', 'VBG', 'IN', 'NP', '.'] \n",
      " ['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'RB', 'IN', 'DT', 'NN', 'NN', 'CC', 'IN', 'DT', 'NN', 'NN', 'IN', 'NP', '.'] \n",
      "\n",
      "\n",
      "\n",
      "There is no capital gains tax in Greece .\n",
      "['There', 'is', 'no', 'capital', 'gains', 'tax', 'in', 'Greece', '.'] \n",
      " ['EX', 'VBZ', 'DT', 'NN', 'NNS', 'NN', 'IN', 'NP', '.'] \n",
      " ['EX', 'VBZ', 'DT', 'NN', 'NNS', 'NN', 'IN', 'NP', '.'] \n",
      "\n",
      "\n",
      "\n",
      "Microsoft Corp. said its board authorized the repurchase of as many as one million common shares from time to time in fiscal 1990 ending June 30 .\n",
      "['Microsoft', 'Corp.', 'said', 'its', 'board', 'authorized', 'the', 'repurchase', 'of', 'as', 'many', 'as', 'one', 'million', 'common', 'shares', 'from', 'time', 'to', 'time', 'in', 'fiscal', '1990', 'ending', 'June', '30', '.'] \n",
      " ['NP', 'NP', 'VBD', 'PP$', 'NN', 'VBD', 'DT', 'VBD', 'IN', 'RB', 'JJ', 'IN', 'CD', 'CD', 'JJ', 'NNS', 'IN', 'NN', 'TO', 'NN', 'IN', 'JJ', 'CD', 'VBG', 'NP', 'CD', '.'] \n",
      " ['NP', 'NP', 'VBD', 'PP$', 'NN', 'VBD', 'DT', 'VBD', 'IN', 'IN', 'JJ', 'IN', 'CD', 'CD', 'JJ', 'NNS', 'IN', 'NN', 'TO', 'NN', 'IN', 'JJ', 'CD', 'VBG', 'NP', 'CD', '.'] \n",
      "\n",
      "\n",
      "\n",
      "The software manufacturer said it planned to buy the shares on the open market to reduce the dilutive effect to shareholders of stock issuances for the company 's stock option and employee-stock purchase plans .\n",
      "['The', 'software', 'manufacturer', 'said', 'it', 'planned', 'to', 'buy', 'the', 'shares', 'on', 'the', 'open', 'market', 'to', 'reduce', 'the', 'dilutive', 'effect', 'to', 'shareholders', 'of', 'stock', 'issuances', 'for', 'the', 'company', \"'s\", 'stock', 'option', 'and', 'employee-stock', 'purchase', 'plans', '.'] \n",
      " ['DT', 'NN', 'NN', 'VBD', 'PP', 'VBD', 'TO', 'VB', 'DT', 'NNS', 'IN', 'DT', 'JJ', 'NN', 'TO', 'VB', 'DT', 'JJ', 'NN', 'TO', 'NNS', 'IN', 'NN', 'NNS', 'IN', 'DT', 'NN', 'POS', 'NN', 'NN', 'CC', 'JJ', 'NN', 'NNS', '.'] \n",
      " ['DT', 'NN', 'NN', 'VBD', 'PP', 'VBD', 'TO', 'VB', 'DT', 'NNS', 'IN', 'DT', 'JJ', 'NN', 'TO', 'VB', 'DT', 'NP', 'NN', 'TO', 'NNS', 'IN', 'NN', 'NP', 'IN', 'DT', 'NN', 'POS', 'NN', 'NN', 'CC', 'NP', 'NN', 'NNS', '.'] \n",
      "\n",
      "\n",
      "\n",
      "The company had 56.2 million average shares outstanding on June 30 .\n",
      "['The', 'company', 'had', '56.2', 'million', 'average', 'shares', 'outstanding', 'on', 'June', '30', '.'] \n",
      " ['DT', 'NN', 'VBD', 'CD', 'CD', 'JJ', 'NNS', 'JJ', 'IN', 'NP', 'CD', '.'] \n",
      " ['DT', 'NN', 'VBD', 'NP', 'CD', 'JJ', 'NNS', 'JJ', 'IN', 'NP', 'CD', '.'] \n",
      "\n",
      "\n",
      "\n",
      "Accuracy: 92.86%\n"
     ]
    }
   ],
   "source": [
    "predicted_sentences = predict_text(test_df.tail(10), word_tag_prob, first_tag_prob, tag_given_tag_prob)\n",
    "# predicted_sentences.to_csv('POS.test.out', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
