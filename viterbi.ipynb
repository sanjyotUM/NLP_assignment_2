{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_colwidth = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('POS.train', sep='\\t', header=None, names=['raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Pierre/NP Vinken/NP ,/, 61/CD years/NNS old/JJ ,/, will/MD join/VB the/DT board/NN as/IN a/DT nonexecutive/JJ director/NN Nov./NP 29/CD ./.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mr./NP Vinken/NP is/VBZ chairman/NN of/IN Elsevier/NP N.V./NP ,/, the/DT Dutch/NP publishing/VBG group/NN ./.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Rudolph/NP Agnew/NP ,/, 55/CD years/NNS old/JJ and/CC former/JJ chairman/NN of/IN Consolidated/NP Gold/NP Fields/NP PLC/NP ,/, was/VBD named/VBN a/DT nonexecutive/JJ director/NN of/IN this/DT British/JJ industrial/JJ conglomerate/NN ./.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A/DT form/NN of/IN asbestos/NN once/RB used/VBN to/TO make/VB Kent/NP cigarette/NN filters/NNS has/VBZ caused/VBN a/DT high/JJ percentage/NN of/IN cancer/NN deaths/NNS among/IN a/DT group/NN of/IN workers/NNS exposed/VBN to/TO it/PP more/RBR than/IN 30/CD years/NNS ago/IN ,/, researchers/NNS rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The/DT asbestos/NN fiber/NN ,/, crocidolite/NN ,/, is/VBZ unusually/RB resilient/JJ once/IN it/PP enters/VBZ the/DT lungs/NNS ,/, with/IN even/RB brief/JJ exposures/NNS to/TO it/PP causing/VBG symptoms/NNS that/WDT show/VBP up/IN decades/NNS later/JJ ,/, researchers/NNS said/VBD ./.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                           raw\n",
       "0                                                                                                                                                                 Pierre/NP Vinken/NP ,/, 61/CD years/NNS old/JJ ,/, will/MD join/VB the/DT board/NN as/IN a/DT nonexecutive/JJ director/NN Nov./NP 29/CD ./. \n",
       "1                                                                                                                                                                                               Mr./NP Vinken/NP is/VBZ chairman/NN of/IN Elsevier/NP N.V./NP ,/, the/DT Dutch/NP publishing/VBG group/NN ./. \n",
       "2                                                                Rudolph/NP Agnew/NP ,/, 55/CD years/NNS old/JJ and/CC former/JJ chairman/NN of/IN Consolidated/NP Gold/NP Fields/NP PLC/NP ,/, was/VBD named/VBN a/DT nonexecutive/JJ director/NN of/IN this/DT British/JJ industrial/JJ conglomerate/NN ./. \n",
       "3  A/DT form/NN of/IN asbestos/NN once/RB used/VBN to/TO make/VB Kent/NP cigarette/NN filters/NNS has/VBZ caused/VBN a/DT high/JJ percentage/NN of/IN cancer/NN deaths/NNS among/IN a/DT group/NN of/IN workers/NNS exposed/VBN to/TO it/PP more/RBR than/IN 30/CD years/NNS ago/IN ,/, researchers/NNS rep...\n",
       "4                 The/DT asbestos/NN fiber/NN ,/, crocidolite/NN ,/, is/VBZ unusually/RB resilient/JJ once/IN it/PP enters/VBZ the/DT lungs/NNS ,/, with/IN even/RB brief/JJ exposures/NNS to/TO it/PP causing/VBG symptoms/NNS that/WDT show/VBP up/IN decades/NNS later/JJ ,/, researchers/NNS said/VBD ./. "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df):\n",
    "    \n",
    "    print('Calculating word given tag probabilities...')\n",
    "    word_tag_prob = (\n",
    "    df\n",
    "    .assign(raw_split = lambda x: x['raw'].str.split())\n",
    "    .drop(['raw'], axis=1)\n",
    "    .explode('raw_split')\n",
    "    .reset_index(drop=True)\n",
    "    .assign(word_tag = lambda x: x['raw_split'].str.split('/'))\n",
    "    .drop(['raw_split'], axis=1)\n",
    "    .assign(\n",
    "        word = lambda x: x['word_tag'].str[0],\n",
    "        tag = lambda x: x['word_tag'].str[1],\n",
    "    )\n",
    "    .drop(['word_tag'], axis=1)\n",
    "    .groupby(by=['word', 'tag'])\n",
    "    .agg({'tag': 'count'})\n",
    "    .rename(columns={'tag': 'count'})\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        tagcount = lambda x: x.groupby(by=['tag'])['count'].transform(sum),\n",
    "        prob = lambda x: x['count']/x.groupby('tag')['count'].transform(sum)\n",
    "    )\n",
    "    .drop(['count', 'tagcount'], axis=1)\n",
    "    .set_index(['word', 'tag'])['prob']\n",
    "    )\n",
    "    \n",
    "    print('Calculating tag given sentence beginning probabilities...')\n",
    "    first_tag_prob = (\n",
    "    df\n",
    "    .assign(first_tag = lambda x: x['raw'].str.split().str[0].str.split('/').str[1])\n",
    "    .groupby(by=['first_tag'])\n",
    "    .agg({'first_tag': 'count'})\n",
    "    .rename(columns={'first_tag': 'count'})\n",
    "    .assign(prob = lambda x: x['count']/x['count'].sum())\n",
    "    .drop(['count'], axis=1)['prob']\n",
    "    )\n",
    "    \n",
    "    print('Calculating tag given previous tag probabilities...')\n",
    "    tag_given_tag_prob = (\n",
    "    df\n",
    "    .assign(eos_tag=' EOS/EOS')\n",
    "    .assign(raw_mod = lambda x: (x['raw'] + x['eos_tag']).astype(str))\n",
    "    .drop(['raw'], axis=1)\n",
    "    .assign(raw_split = lambda x: x['raw_mod'].str.split())\n",
    "    .drop(['raw_mod', 'eos_tag'], axis=1)\n",
    "    .explode('raw_split')\n",
    "    .reset_index(drop=True)\n",
    "    .assign(given = lambda x: x['raw_split'].str.split('/').str[1])\n",
    "    .drop(['raw_split'], axis=1)\n",
    "    .assign(asked = lambda x: x['given'].shift(-1)).fillna('EndOfDocument')\n",
    "    .groupby(by=['asked', 'given'])\n",
    "    .agg({'asked': 'count'})\n",
    "    .rename(columns={'asked': 'count'})\n",
    "    .reset_index()\n",
    "    .assign(prob = lambda x: x['count']/x.groupby(by=['given'])['count'].transform(sum))\n",
    "    .set_index(['asked', 'given'])['prob']\n",
    "    )\n",
    "    print('Done.')\n",
    "    return word_tag_prob, first_tag_prob, tag_given_tag_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating word given tag probabilities...\n",
      "Calculating tag given sentence beginning probabilities...\n",
      "Calculating tag given previous tag probabilities...\n",
      "Done.\n",
      "CPU times: user 1.78 s, sys: 110 ms, total: 1.89 s\n",
      "Wall time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_tag_prob, first_tag_prob, tag_given_tag_prob = train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08784517347179609"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tag_prob[('The', 'DT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(sentence, word_tag_prob, first_tag_prob, tag_given_tag_prob):\n",
    "    \n",
    "    def get_word_tag_prob(word, tag):\n",
    "        try:\n",
    "            return word_tag_prob[(word, tag)]\n",
    "        except:\n",
    "            return 1.0\n",
    "    \n",
    "    def get_tag_set(word):\n",
    "        try:\n",
    "            return word_tag_prob[word].index.tolist()\n",
    "        except:\n",
    "            return ['NN']\n",
    "    \n",
    "    def get_tag_given_tag_prob(this_tag, given_tag):\n",
    "        try:\n",
    "            return tag_given_tag_prob[(this_tag, given_tag)]\n",
    "        except KeyError:\n",
    "            return 0.0\n",
    "    \n",
    "    score = dict()\n",
    "    back_ptr = dict()\n",
    "    sentence_list = sentence.split()\n",
    "    \n",
    "    # Initialization\n",
    "    first_word_tag_set = get_tag_set(sentence_list[0])\n",
    "    for tag in first_word_tag_set:\n",
    "        score[(tag, 0)] = get_word_tag_prob(sentence_list[0], tag)\n",
    "        back_ptr[(tag, 0)] = 0\n",
    "    \n",
    "    # Iteration\n",
    "    for j, word in enumerate(sentence_list[1:]):\n",
    "        for tag in get_tag_set(word):\n",
    "            i = j + 1\n",
    "            prev_word_tag_set = get_tag_set(sentence_list[i-1])\n",
    "            t1 = get_word_tag_prob(word, tag)\n",
    "            t2_dict = {last_tag: score[(last_tag, i-1)] * get_tag_given_tag_prob(tag, last_tag) \n",
    "                       for last_tag in prev_word_tag_set}\n",
    "            t2 = max(t2_dict.values())\n",
    "            score[(tag, i)] = t1 * t2\n",
    "            back_ptr[(tag, i)] = max(t2_dict)\n",
    "\n",
    "    final_word_tag_set = get_tag_set(sentence_list[-1])\n",
    "    last_scores = {tag: score[(tag, len(sentence_list) - 1)] for tag in final_word_tag_set}\n",
    "    final_word_tag = max(last_scores)\n",
    "    \n",
    "    final_tags = [final_word_tag]\n",
    "    this_tag = final_word_tag\n",
    "    for i in reversed(range(len(sentence_list))):\n",
    "        final_tags.append(back_ptr[(this_tag, i)])\n",
    "        this_tag = back_ptr[(this_tag, i)]\n",
    "    \n",
    "    return final_tags[::-1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MD', 'PP', 'VBP', 'DT']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Can you feel this'\n",
    "predict_sentence(sentence, word_tag_prob, first_tag_prob, tag_given_tag_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words given tags\n",
    "# Tags given beginning of sentence\n",
    "# Tags given previous tag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
